{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "prop718_sampling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkdfoOEjgMZr"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, models\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import os\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXMyGPSgMZ0"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMmnd2C9gMZ2"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiAkgpSlgMZ3"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY9WI-9_gMZ4"
      },
      "source": [
        "def build(input_shape, no_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    ##\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    ##\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    ##\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    ##\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(no_classes, activation='softmax'))\n",
        "    ##\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CadN7ok6gMZ5"
      },
      "source": [
        "model = build(x_train.shape[1:], 10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L92akJejgMZ6"
      },
      "source": [
        "# model.summary()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWxAn4SsgMZ6"
      },
      "source": [
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJsk_Rq6gMZ8",
        "outputId": "ed436bf6-b560-472d-ed22-0d90618f0189"
      },
      "source": [
        "import time\n",
        "##\n",
        "convergence_accuracy_diff = 0.002\n",
        "set_size = x_train.shape[0]\n",
        "train_set_errors = []\n",
        "test_set_errors = []\n",
        "training_time_to_convergence = []\n",
        "##########\n",
        "for downsampling_ratio in range(2,21,2):\n",
        "  sample_no = np.arange(set_size)\n",
        "  sample_no = np.random.choice(sample_no, int(set_size/downsampling_ratio), replace=False)\n",
        "  x_train_new = x_train[sample_no]\n",
        "  y_train_new = y_train[sample_no]\n",
        "  mean = np.mean(x_train_new,axis=(0,1,2,3))\n",
        "  std = np.std(x_train_new,axis=(0,1,2,3))\n",
        "  x_train_new = (x_train_new-mean)/(std+1e-7)\n",
        "  x_test = (x_test-mean)/(std+1e-7)\n",
        "  converge = False\n",
        "  old_acc = 0\n",
        "  num_epoch_to_converge = 0\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  train_error_curve = []\n",
        "  test_error_curve = []\n",
        "  train_time = 0\n",
        "  start = time.time()\n",
        "  while converge==False:\n",
        "    num_epoch_to_converge += 1\n",
        "    start = time.time()\n",
        "    hist = model.fit(x_train_new, y_train_new, batch_size=64, epochs=1, verbose=1)\n",
        "    end = time.time()\n",
        "    train_time += (end - start)\n",
        "    new_acc = hist.history['accuracy'][-1]\n",
        "    if (new_acc - old_acc) < convergence_accuracy_diff:\n",
        "      converge = True\n",
        "    old_acc = new_acc\n",
        "    new_train_error = (1 - new_acc)*100\n",
        "    train_error_curve.append(new_train_error)\n",
        "    ##\n",
        "    _, new_test_accuracy = model.evaluate(x_test, y_test)\n",
        "    new_test_error = (1 - new_test_accuracy)*100\n",
        "    test_error_curve.append(new_test_error)\n",
        "    ##\n",
        "  train_set_errors.append(train_error_curve)\n",
        "  test_set_errors.append(test_error_curve)\n",
        "  training_time_to_convergence.append(train_time)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 7s 10ms/step - loss: 2.0413 - accuracy: 0.3263\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.1342 - accuracy: 0.3285\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.2571 - accuracy: 0.5466\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1442 - accuracy: 0.5939\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 1.0341 - accuracy: 0.6290\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0735 - accuracy: 0.6292\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.8922 - accuracy: 0.6829\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9898 - accuracy: 0.6619\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7818 - accuracy: 0.7216\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7878 - accuracy: 0.7288\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6987 - accuracy: 0.7523\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7380 - accuracy: 0.7489\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.6352 - accuracy: 0.7762\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6860 - accuracy: 0.7675\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5770 - accuracy: 0.7960\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6654 - accuracy: 0.7741\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.5277 - accuracy: 0.8116\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6575 - accuracy: 0.7841\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4865 - accuracy: 0.8253\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6973 - accuracy: 0.7737\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4424 - accuracy: 0.8418\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6986 - accuracy: 0.7787\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.4058 - accuracy: 0.8562\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6842 - accuracy: 0.7856\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3665 - accuracy: 0.8706\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7022 - accuracy: 0.7847\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3520 - accuracy: 0.8730\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6639 - accuracy: 0.8045\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.3179 - accuracy: 0.8860\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6687 - accuracy: 0.7984\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2949 - accuracy: 0.8950\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6658 - accuracy: 0.8019\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2749 - accuracy: 0.9023\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.7988\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2521 - accuracy: 0.9089\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7161 - accuracy: 0.7965\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2359 - accuracy: 0.9153\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7323 - accuracy: 0.8022\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2196 - accuracy: 0.9208\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7035 - accuracy: 0.8075\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2139 - accuracy: 0.9233\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7275 - accuracy: 0.8040\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1926 - accuracy: 0.9313\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7582 - accuracy: 0.8032\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1875 - accuracy: 0.9336\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7473 - accuracy: 0.8103\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1797 - accuracy: 0.9358\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7754 - accuracy: 0.8092\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1681 - accuracy: 0.9405\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7962 - accuracy: 0.8094\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1569 - accuracy: 0.9453\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7884 - accuracy: 0.8022\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1625 - accuracy: 0.9431\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7977 - accuracy: 0.8083\n",
            "196/196 [==============================] - 3s 11ms/step - loss: 0.5059 - accuracy: 0.8572\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 9.0781 - accuracy: 0.1044\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.3406 - accuracy: 0.8893\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 10.0649 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.2621 - accuracy: 0.9133\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 20.1780 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.2253 - accuracy: 0.9213\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 14.1850 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.1994 - accuracy: 0.9312\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 12.1964 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.1811 - accuracy: 0.9375\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 11.1189 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.1596 - accuracy: 0.9443\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 10.4624 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 11ms/step - loss: 0.1445 - accuracy: 0.9492\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 18.9548 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.1344 - accuracy: 0.9518\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 24.2329 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.1190 - accuracy: 0.9591\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 14.2571 - accuracy: 0.1000\n",
            "196/196 [==============================] - 2s 10ms/step - loss: 0.1252 - accuracy: 0.9582\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 19.8164 - accuracy: 0.1000\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 0.5119 - accuracy: 0.8501\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 17.9864 - accuracy: 0.1000\n",
            "131/131 [==============================] - 1s 10ms/step - loss: 0.3007 - accuracy: 0.9002\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 20.1578 - accuracy: 0.1000\n",
            "131/131 [==============================] - 1s 10ms/step - loss: 0.2235 - accuracy: 0.9248\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 27.2920 - accuracy: 0.1000\n",
            "131/131 [==============================] - 1s 10ms/step - loss: 0.1990 - accuracy: 0.9312\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 29.2191 - accuracy: 0.1000\n",
            "131/131 [==============================] - 1s 10ms/step - loss: 0.1539 - accuracy: 0.9489\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 23.7466 - accuracy: 0.1000\n",
            "131/131 [==============================] - 1s 10ms/step - loss: 0.1434 - accuracy: 0.9508\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 25.9235 - accuracy: 0.1000\n",
            "98/98 [==============================] - 2s 12ms/step - loss: 0.4421 - accuracy: 0.8718\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 19.8939 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.2486 - accuracy: 0.9158\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 16.6523 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9344\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 21.9737 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1683 - accuracy: 0.9429\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 24.6767 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1462 - accuracy: 0.9506\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 33.9807 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9597\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 41.9155 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0882 - accuracy: 0.9715\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 38.5533 - accuracy: 0.1000\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.0946 - accuracy: 0.9706\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 13.3742 - accuracy: 0.1000\n",
            "79/79 [==============================] - 2s 13ms/step - loss: 0.4829 - accuracy: 0.8632\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 26.3510 - accuracy: 0.1000\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.2378 - accuracy: 0.9176\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 24.7038 - accuracy: 0.1000\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.1973 - accuracy: 0.9344\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 14.3797 - accuracy: 0.1000\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.1455 - accuracy: 0.9482\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 32.8715 - accuracy: 0.1000\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.1284 - accuracy: 0.9562\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 58.7163 - accuracy: 0.1000\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.1023 - accuracy: 0.9660\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 40.6063 - accuracy: 0.1000\n",
            "79/79 [==============================] - 1s 10ms/step - loss: 0.0999 - accuracy: 0.9662\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 30.5194 - accuracy: 0.1000\n",
            "66/66 [==============================] - 2s 14ms/step - loss: 0.4946 - accuracy: 0.8650\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 15.0784 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.2679 - accuracy: 0.9126\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 28.8799 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.2014 - accuracy: 0.9333\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 22.4965 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.1650 - accuracy: 0.9429\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 13.5851 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.1202 - accuracy: 0.9611\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 20.0294 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.0949 - accuracy: 0.9674\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 30.0215 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.0794 - accuracy: 0.9726\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 22.1749 - accuracy: 0.1000\n",
            "66/66 [==============================] - 1s 10ms/step - loss: 0.0830 - accuracy: 0.9741\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 17.7686 - accuracy: 0.1000\n",
            "56/56 [==============================] - 2s 14ms/step - loss: 0.4941 - accuracy: 0.8658\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 19.0053 - accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.2562 - accuracy: 0.9107\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 34.1375 - accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.1885 - accuracy: 0.9325\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 28.9967 - accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.1369 - accuracy: 0.9541\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 24.5464 - accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.1071 - accuracy: 0.9639\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 25.0250 - accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 11ms/step - loss: 0.0884 - accuracy: 0.9740\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 29.8424 - accuracy: 0.1000\n",
            "56/56 [==============================] - 1s 10ms/step - loss: 0.0852 - accuracy: 0.9703\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 35.5065 - accuracy: 0.1000\n",
            "49/49 [==============================] - 2s 15ms/step - loss: 0.5185 - accuracy: 0.8703\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 28.0618 - accuracy: 0.1000\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 0.2299 - accuracy: 0.9200\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 23.6206 - accuracy: 0.1000\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 0.1703 - accuracy: 0.9421\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 35.0062 - accuracy: 0.1000\n",
            "49/49 [==============================] - 0s 10ms/step - loss: 0.1216 - accuracy: 0.9568\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 34.7737 - accuracy: 0.1000\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 0.0978 - accuracy: 0.9709\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 46.6746 - accuracy: 0.1000\n",
            "49/49 [==============================] - 1s 10ms/step - loss: 0.0990 - accuracy: 0.9680\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 45.5247 - accuracy: 0.1000\n",
            "44/44 [==============================] - 2s 15ms/step - loss: 0.4714 - accuracy: 0.8768\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 19.3576 - accuracy: 0.1000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.2609 - accuracy: 0.9136\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 23.1709 - accuracy: 0.1000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.1728 - accuracy: 0.9384\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 15.5533 - accuracy: 0.1000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.1265 - accuracy: 0.9553\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 26.2771 - accuracy: 0.1000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9676\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 24.4516 - accuracy: 0.1000\n",
            "44/44 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.9676\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 31.9455 - accuracy: 0.1000\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.4353 - accuracy: 0.8655\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 27.2359 - accuracy: 0.1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.2770 - accuracy: 0.9080\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 30.0027 - accuracy: 0.1000\n",
            "40/40 [==============================] - 0s 11ms/step - loss: 0.1408 - accuracy: 0.9512\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 27.5282 - accuracy: 0.1000\n",
            "40/40 [==============================] - 0s 10ms/step - loss: 0.1385 - accuracy: 0.9508\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 33.4588 - accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-ejkK7bCpm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txFkfrFHgMZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2a3195-61d7-465d-ba4b-5dad3813654e"
      },
      "source": [
        "    #train error\n",
        "    _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "    train_error = (1 - train_accuracy)*100\n",
        "    #test_error\n",
        "    _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "    test_error = (1 - test_accuracy)*100\n",
        "# print('train error = {}\\ntest error = {}'.format(train_error,test_error))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 5s 3ms/step - loss: 10.6315 - accuracy: 0.2739\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 33.4588 - accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fikbq0tQgMZ_"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}