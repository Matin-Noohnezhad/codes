{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "#Transfering data to GPU memory will take time and we only do it, if we really need to use GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],-1) #reshape 2D image into a 1D vector\n",
    "x_test = x_test.reshape(x_test.shape[0], -1) #reshape 2D image into a 1D vector\n",
    "##\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the input vectors\n",
    "mean = np.mean(x_train)\n",
    "std = np.std(x_train)\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the output to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, no_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape_of_input, no_classes, no_hidden_layers=0, no_units_per_layer=50):\n",
    "    model = Sequential()\n",
    "    if (no_hidden_layers == 0):\n",
    "        model.add(Dense(no_classes, input_shape = shape_of_input, name='output_layer', activation='softmax'))\n",
    "        return model\n",
    "    model.add(Dense(no_units_per_layer, input_shape = shape_of_input,  activation='relu'))\n",
    "    for i in range(no_hidden_layers-1):\n",
    "        model.add(Dense(no_units_per_layer, activation='relu'))\n",
    "    model.add(Dense(no_classes, name='output_layer', activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "output_layer (Dense)         (None, 10)                30730     \n",
      "=================================================================\n",
      "Total params: 30,730\n",
      "Trainable params: 30,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 hidden layers\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.9549 - accuracy: 0.3415 - val_loss: 1.8742 - val_accuracy: 0.3578\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.8500 - accuracy: 0.3724 - val_loss: 1.8735 - val_accuracy: 0.3766\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.8199 - accuracy: 0.3844 - val_loss: 1.8603 - val_accuracy: 0.3621\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.8001 - accuracy: 0.3903 - val_loss: 1.8924 - val_accuracy: 0.3624\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7960 - accuracy: 0.3914 - val_loss: 1.8760 - val_accuracy: 0.3643\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7855 - accuracy: 0.3956 - val_loss: 1.8546 - val_accuracy: 0.3756\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7784 - accuracy: 0.3978 - val_loss: 1.8419 - val_accuracy: 0.3648\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7740 - accuracy: 0.4012 - val_loss: 1.8991 - val_accuracy: 0.3714\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7701 - accuracy: 0.4008 - val_loss: 1.8921 - val_accuracy: 0.3541\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7635 - accuracy: 0.4010 - val_loss: 1.8808 - val_accuracy: 0.3595\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7582 - accuracy: 0.4039 - val_loss: 1.8746 - val_accuracy: 0.3702\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7621 - accuracy: 0.4035 - val_loss: 1.8545 - val_accuracy: 0.3775\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7469 - accuracy: 0.4082 - val_loss: 1.8862 - val_accuracy: 0.3651\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7501 - accuracy: 0.4096 - val_loss: 1.8778 - val_accuracy: 0.3668\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7447 - accuracy: 0.4103 - val_loss: 1.8972 - val_accuracy: 0.3597\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7497 - accuracy: 0.4082 - val_loss: 1.8872 - val_accuracy: 0.3551\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7425 - accuracy: 0.4094 - val_loss: 1.8729 - val_accuracy: 0.3761\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7356 - accuracy: 0.4102 - val_loss: 1.8854 - val_accuracy: 0.3730\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7412 - accuracy: 0.4090 - val_loss: 1.8848 - val_accuracy: 0.3703\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7388 - accuracy: 0.4121 - val_loss: 1.9850 - val_accuracy: 0.3410\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7399 - accuracy: 0.4129 - val_loss: 1.8970 - val_accuracy: 0.3655\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7304 - accuracy: 0.4158 - val_loss: 1.9156 - val_accuracy: 0.3588\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7317 - accuracy: 0.4146 - val_loss: 1.9337 - val_accuracy: 0.3452\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7266 - accuracy: 0.4150 - val_loss: 1.8811 - val_accuracy: 0.3759\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7227 - accuracy: 0.4161 - val_loss: 1.9404 - val_accuracy: 0.3572\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7286 - accuracy: 0.4150 - val_loss: 1.9460 - val_accuracy: 0.3463\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7319 - accuracy: 0.4150 - val_loss: 1.9722 - val_accuracy: 0.3482\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7226 - accuracy: 0.4179 - val_loss: 1.9490 - val_accuracy: 0.3546\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7155 - accuracy: 0.4163 - val_loss: 1.9038 - val_accuracy: 0.3738\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7253 - accuracy: 0.4160 - val_loss: 1.9255 - val_accuracy: 0.3611\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7290 - accuracy: 0.4166 - val_loss: 1.9050 - val_accuracy: 0.3635\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7197 - accuracy: 0.4174 - val_loss: 1.9494 - val_accuracy: 0.3536\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7200 - accuracy: 0.4200 - val_loss: 1.9470 - val_accuracy: 0.3544\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7201 - accuracy: 0.4205 - val_loss: 1.8809 - val_accuracy: 0.3676\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7272 - accuracy: 0.4158 - val_loss: 1.9927 - val_accuracy: 0.3676\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7094 - accuracy: 0.4221 - val_loss: 1.9416 - val_accuracy: 0.3584\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7172 - accuracy: 0.4175 - val_loss: 1.9479 - val_accuracy: 0.3562\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7094 - accuracy: 0.4209 - val_loss: 1.9339 - val_accuracy: 0.3500\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7075 - accuracy: 0.4224 - val_loss: 1.9103 - val_accuracy: 0.3640\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7107 - accuracy: 0.4213 - val_loss: 1.9174 - val_accuracy: 0.3586\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7118 - accuracy: 0.4195 - val_loss: 1.9455 - val_accuracy: 0.3568\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7127 - accuracy: 0.4205 - val_loss: 1.9759 - val_accuracy: 0.3351\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7102 - accuracy: 0.4210 - val_loss: 1.9102 - val_accuracy: 0.3623\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7131 - accuracy: 0.4208 - val_loss: 1.9089 - val_accuracy: 0.3722\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7084 - accuracy: 0.4187 - val_loss: 1.9061 - val_accuracy: 0.3700\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7036 - accuracy: 0.4238 - val_loss: 1.9382 - val_accuracy: 0.3444\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7001 - accuracy: 0.4232 - val_loss: 1.9525 - val_accuracy: 0.3632\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7118 - accuracy: 0.4199 - val_loss: 1.9490 - val_accuracy: 0.3627\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7082 - accuracy: 0.4202 - val_loss: 1.9528 - val_accuracy: 0.3518\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 1.7092 - accuracy: 0.4227 - val_loss: 1.9096 - val_accuracy: 0.3721\n",
      "1563/1563 [==============================] - 1s 727us/step - loss: 1.6400 - accuracy: 0.4431\n",
      "313/313 [==============================] - 0s 724us/step - loss: 1.9096 - accuracy: 0.3721\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 154,160\n",
      "Trainable params: 154,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1 hidden layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.8379 - accuracy: 0.3792 - val_loss: 1.6781 - val_accuracy: 0.4185\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5771 - accuracy: 0.4595 - val_loss: 1.5775 - val_accuracy: 0.4553\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4799 - accuracy: 0.4855 - val_loss: 1.5253 - val_accuracy: 0.4699\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4114 - accuracy: 0.5088 - val_loss: 1.4871 - val_accuracy: 0.4791\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3700 - accuracy: 0.5235 - val_loss: 1.4986 - val_accuracy: 0.4784\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3443 - accuracy: 0.5302 - val_loss: 1.4844 - val_accuracy: 0.4836\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3151 - accuracy: 0.5381 - val_loss: 1.5098 - val_accuracy: 0.4719\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2955 - accuracy: 0.5475 - val_loss: 1.4895 - val_accuracy: 0.4842\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2805 - accuracy: 0.5528 - val_loss: 1.4677 - val_accuracy: 0.4913\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2563 - accuracy: 0.5603 - val_loss: 1.4487 - val_accuracy: 0.5028\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2463 - accuracy: 0.5615 - val_loss: 1.4692 - val_accuracy: 0.4935\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2339 - accuracy: 0.5662 - val_loss: 1.4598 - val_accuracy: 0.4956\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2158 - accuracy: 0.5745 - val_loss: 1.4679 - val_accuracy: 0.4890\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2039 - accuracy: 0.5778 - val_loss: 1.5026 - val_accuracy: 0.4832\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1925 - accuracy: 0.5808 - val_loss: 1.4847 - val_accuracy: 0.4890\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1807 - accuracy: 0.5835 - val_loss: 1.4879 - val_accuracy: 0.4941\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1666 - accuracy: 0.5885 - val_loss: 1.4857 - val_accuracy: 0.4931\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1576 - accuracy: 0.5932 - val_loss: 1.4882 - val_accuracy: 0.4875\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1471 - accuracy: 0.5961 - val_loss: 1.4899 - val_accuracy: 0.4917\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1380 - accuracy: 0.5974 - val_loss: 1.5204 - val_accuracy: 0.4825\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1260 - accuracy: 0.6016 - val_loss: 1.5123 - val_accuracy: 0.4865\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1130 - accuracy: 0.6074 - val_loss: 1.5459 - val_accuracy: 0.4866\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1092 - accuracy: 0.6093 - val_loss: 1.5207 - val_accuracy: 0.4885\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0988 - accuracy: 0.6131 - val_loss: 1.5283 - val_accuracy: 0.4904\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0924 - accuracy: 0.6150 - val_loss: 1.5324 - val_accuracy: 0.4881\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0847 - accuracy: 0.6166 - val_loss: 1.5304 - val_accuracy: 0.4880\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0749 - accuracy: 0.6191 - val_loss: 1.5377 - val_accuracy: 0.4908\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0663 - accuracy: 0.6236 - val_loss: 1.5508 - val_accuracy: 0.4879\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0570 - accuracy: 0.6269 - val_loss: 1.5728 - val_accuracy: 0.4838\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0526 - accuracy: 0.6302 - val_loss: 1.5771 - val_accuracy: 0.4824\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0450 - accuracy: 0.6313 - val_loss: 1.5525 - val_accuracy: 0.4875\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0347 - accuracy: 0.6338 - val_loss: 1.5635 - val_accuracy: 0.4825\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0300 - accuracy: 0.6358 - val_loss: 1.5638 - val_accuracy: 0.4871\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0223 - accuracy: 0.6377 - val_loss: 1.5700 - val_accuracy: 0.4862\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0167 - accuracy: 0.6378 - val_loss: 1.5888 - val_accuracy: 0.4821\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0103 - accuracy: 0.6424 - val_loss: 1.5935 - val_accuracy: 0.4794\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0023 - accuracy: 0.6457 - val_loss: 1.6177 - val_accuracy: 0.4814\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9965 - accuracy: 0.6474 - val_loss: 1.6216 - val_accuracy: 0.4779\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9842 - accuracy: 0.6504 - val_loss: 1.6171 - val_accuracy: 0.4835\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9848 - accuracy: 0.6506 - val_loss: 1.6322 - val_accuracy: 0.4712\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9777 - accuracy: 0.6530 - val_loss: 1.6662 - val_accuracy: 0.4705\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9741 - accuracy: 0.6550 - val_loss: 1.6467 - val_accuracy: 0.4735\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9668 - accuracy: 0.6571 - val_loss: 1.6607 - val_accuracy: 0.4804\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9561 - accuracy: 0.6620 - val_loss: 1.6678 - val_accuracy: 0.4718\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9589 - accuracy: 0.6589 - val_loss: 1.7207 - val_accuracy: 0.4682\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9580 - accuracy: 0.6604 - val_loss: 1.6805 - val_accuracy: 0.4727\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9466 - accuracy: 0.6629 - val_loss: 1.6837 - val_accuracy: 0.4724\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9415 - accuracy: 0.6659 - val_loss: 1.6915 - val_accuracy: 0.4806\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9332 - accuracy: 0.6698 - val_loss: 1.7078 - val_accuracy: 0.4705\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9283 - accuracy: 0.6707 - val_loss: 1.7096 - val_accuracy: 0.4655\n",
      "1563/1563 [==============================] - 1s 928us/step - loss: 0.8822 - accuracy: 0.6853\n",
      "313/313 [==============================] - 0s 890us/step - loss: 1.7096 - accuracy: 0.4655\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 156,710\n",
      "Trainable params: 156,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2 hidden layers\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7782 - accuracy: 0.3781 - val_loss: 1.5957 - val_accuracy: 0.4424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5633 - accuracy: 0.4479 - val_loss: 1.5618 - val_accuracy: 0.4511\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4745 - accuracy: 0.4822 - val_loss: 1.4989 - val_accuracy: 0.4779\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4171 - accuracy: 0.5025 - val_loss: 1.4847 - val_accuracy: 0.4808\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3680 - accuracy: 0.5200 - val_loss: 1.4753 - val_accuracy: 0.4830\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3273 - accuracy: 0.5346 - val_loss: 1.4503 - val_accuracy: 0.4920\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2993 - accuracy: 0.5443 - val_loss: 1.4350 - val_accuracy: 0.5042\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2675 - accuracy: 0.5547 - val_loss: 1.4576 - val_accuracy: 0.4948\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2493 - accuracy: 0.5611 - val_loss: 1.4359 - val_accuracy: 0.5047\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2270 - accuracy: 0.5687 - val_loss: 1.4327 - val_accuracy: 0.5018\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2014 - accuracy: 0.5760 - val_loss: 1.4242 - val_accuracy: 0.5102\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1825 - accuracy: 0.5839 - val_loss: 1.4709 - val_accuracy: 0.4944\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1671 - accuracy: 0.5896 - val_loss: 1.4436 - val_accuracy: 0.5062\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1519 - accuracy: 0.5929 - val_loss: 1.4578 - val_accuracy: 0.4962\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1396 - accuracy: 0.6005 - val_loss: 1.4571 - val_accuracy: 0.5025\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1194 - accuracy: 0.6055 - val_loss: 1.4613 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1064 - accuracy: 0.6120 - val_loss: 1.4768 - val_accuracy: 0.5024\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0918 - accuracy: 0.6161 - val_loss: 1.4787 - val_accuracy: 0.5005\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0830 - accuracy: 0.6190 - val_loss: 1.4980 - val_accuracy: 0.4943\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0712 - accuracy: 0.6223 - val_loss: 1.4883 - val_accuracy: 0.5007\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0556 - accuracy: 0.6283 - val_loss: 1.4987 - val_accuracy: 0.4961\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0487 - accuracy: 0.6309 - val_loss: 1.5308 - val_accuracy: 0.4911\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0362 - accuracy: 0.6355 - val_loss: 1.5086 - val_accuracy: 0.4935\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0247 - accuracy: 0.6396 - val_loss: 1.5327 - val_accuracy: 0.4931\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0130 - accuracy: 0.6396 - val_loss: 1.5422 - val_accuracy: 0.4977\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0039 - accuracy: 0.6440 - val_loss: 1.5473 - val_accuracy: 0.4904\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9916 - accuracy: 0.6499 - val_loss: 1.5598 - val_accuracy: 0.4968\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9849 - accuracy: 0.6536 - val_loss: 1.5806 - val_accuracy: 0.4858\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9789 - accuracy: 0.6532 - val_loss: 1.5905 - val_accuracy: 0.4885\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9725 - accuracy: 0.6567 - val_loss: 1.6357 - val_accuracy: 0.4743\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9606 - accuracy: 0.6574 - val_loss: 1.5938 - val_accuracy: 0.4915\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9577 - accuracy: 0.6609 - val_loss: 1.6023 - val_accuracy: 0.4931\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9451 - accuracy: 0.6644 - val_loss: 1.6174 - val_accuracy: 0.4886\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9396 - accuracy: 0.6670 - val_loss: 1.6206 - val_accuracy: 0.4832\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9326 - accuracy: 0.6696 - val_loss: 1.6653 - val_accuracy: 0.4835\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9212 - accuracy: 0.6734 - val_loss: 1.6658 - val_accuracy: 0.4891\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9147 - accuracy: 0.6752 - val_loss: 1.6825 - val_accuracy: 0.4859\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9098 - accuracy: 0.6770 - val_loss: 1.6761 - val_accuracy: 0.4891\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9015 - accuracy: 0.6803 - val_loss: 1.7048 - val_accuracy: 0.4862\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8901 - accuracy: 0.6829 - val_loss: 1.6728 - val_accuracy: 0.4863\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8875 - accuracy: 0.6851 - val_loss: 1.7347 - val_accuracy: 0.4821\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8848 - accuracy: 0.6861 - val_loss: 1.7229 - val_accuracy: 0.4802\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8716 - accuracy: 0.6918 - val_loss: 1.7625 - val_accuracy: 0.4773\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8691 - accuracy: 0.6908 - val_loss: 1.7204 - val_accuracy: 0.4823\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8607 - accuracy: 0.6933 - val_loss: 1.7360 - val_accuracy: 0.4845\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8564 - accuracy: 0.6971 - val_loss: 1.7849 - val_accuracy: 0.4747\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8527 - accuracy: 0.6954 - val_loss: 1.7724 - val_accuracy: 0.4747\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8461 - accuracy: 0.7013 - val_loss: 1.7884 - val_accuracy: 0.4741\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8388 - accuracy: 0.7020 - val_loss: 1.8051 - val_accuracy: 0.4758\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8285 - accuracy: 0.7047 - val_loss: 1.8315 - val_accuracy: 0.4768\n",
      "1563/1563 [==============================] - 1s 926us/step - loss: 0.8040 - accuracy: 0.7150\n",
      "313/313 [==============================] - 0s 912us/step - loss: 1.8315 - accuracy: 0.4768\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 159,260\n",
      "Trainable params: 159,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3 hidden layers\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7654 - accuracy: 0.3745 - val_loss: 1.6079 - val_accuracy: 0.4330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5544 - accuracy: 0.4526 - val_loss: 1.5353 - val_accuracy: 0.4595\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4749 - accuracy: 0.4816 - val_loss: 1.5040 - val_accuracy: 0.4705\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4137 - accuracy: 0.4999 - val_loss: 1.4722 - val_accuracy: 0.4813\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3651 - accuracy: 0.5174 - val_loss: 1.4768 - val_accuracy: 0.4844\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3217 - accuracy: 0.5315 - val_loss: 1.4500 - val_accuracy: 0.4943\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2883 - accuracy: 0.5445 - val_loss: 1.4696 - val_accuracy: 0.4848\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2652 - accuracy: 0.5534 - val_loss: 1.4592 - val_accuracy: 0.4927\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2335 - accuracy: 0.5628 - val_loss: 1.4552 - val_accuracy: 0.4970\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2123 - accuracy: 0.5704 - val_loss: 1.4615 - val_accuracy: 0.4914\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1890 - accuracy: 0.5787 - val_loss: 1.4715 - val_accuracy: 0.4896\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1660 - accuracy: 0.5860 - val_loss: 1.4628 - val_accuracy: 0.5026\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1448 - accuracy: 0.5935 - val_loss: 1.4628 - val_accuracy: 0.5014\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1295 - accuracy: 0.6006 - val_loss: 1.4782 - val_accuracy: 0.4933\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1155 - accuracy: 0.6016 - val_loss: 1.4864 - val_accuracy: 0.4950\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0978 - accuracy: 0.6080 - val_loss: 1.4925 - val_accuracy: 0.4941\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0849 - accuracy: 0.6148 - val_loss: 1.4935 - val_accuracy: 0.4995\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0672 - accuracy: 0.6223 - val_loss: 1.5143 - val_accuracy: 0.4914\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0562 - accuracy: 0.6218 - val_loss: 1.5289 - val_accuracy: 0.4885\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0423 - accuracy: 0.6283 - val_loss: 1.5071 - val_accuracy: 0.4989\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0327 - accuracy: 0.6315 - val_loss: 1.5460 - val_accuracy: 0.4998\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0154 - accuracy: 0.6360 - val_loss: 1.5480 - val_accuracy: 0.4960\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0088 - accuracy: 0.6399 - val_loss: 1.5827 - val_accuracy: 0.4901\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9949 - accuracy: 0.6444 - val_loss: 1.5746 - val_accuracy: 0.4910\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9860 - accuracy: 0.6500 - val_loss: 1.5821 - val_accuracy: 0.4921\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9751 - accuracy: 0.6503 - val_loss: 1.6058 - val_accuracy: 0.4890\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9662 - accuracy: 0.6559 - val_loss: 1.5875 - val_accuracy: 0.4922\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9566 - accuracy: 0.6585 - val_loss: 1.6228 - val_accuracy: 0.4894\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9433 - accuracy: 0.6626 - val_loss: 1.6149 - val_accuracy: 0.4894\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9388 - accuracy: 0.6612 - val_loss: 1.6435 - val_accuracy: 0.4862\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9274 - accuracy: 0.6696 - val_loss: 1.6497 - val_accuracy: 0.4887\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9201 - accuracy: 0.6705 - val_loss: 1.6672 - val_accuracy: 0.4800\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9106 - accuracy: 0.6731 - val_loss: 1.6715 - val_accuracy: 0.4836\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9021 - accuracy: 0.6758 - val_loss: 1.7056 - val_accuracy: 0.4806\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8911 - accuracy: 0.6819 - val_loss: 1.7287 - val_accuracy: 0.4851\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8865 - accuracy: 0.6833 - val_loss: 1.7368 - val_accuracy: 0.4813\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8782 - accuracy: 0.6861 - val_loss: 1.7419 - val_accuracy: 0.4825\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8696 - accuracy: 0.6870 - val_loss: 1.7401 - val_accuracy: 0.4766\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8636 - accuracy: 0.6898 - val_loss: 1.7713 - val_accuracy: 0.4792\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8581 - accuracy: 0.6913 - val_loss: 1.7913 - val_accuracy: 0.4759\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8512 - accuracy: 0.6950 - val_loss: 1.7917 - val_accuracy: 0.4793\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8473 - accuracy: 0.6943 - val_loss: 1.7924 - val_accuracy: 0.4819\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8333 - accuracy: 0.7017 - val_loss: 1.8337 - val_accuracy: 0.4768\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8268 - accuracy: 0.7040 - val_loss: 1.8304 - val_accuracy: 0.4829\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8239 - accuracy: 0.7039 - val_loss: 1.8403 - val_accuracy: 0.4774\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8182 - accuracy: 0.7062 - val_loss: 1.8536 - val_accuracy: 0.4734\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8117 - accuracy: 0.7096 - val_loss: 1.8480 - val_accuracy: 0.4769\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8034 - accuracy: 0.7113 - val_loss: 1.8792 - val_accuracy: 0.4674\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7932 - accuracy: 0.7156 - val_loss: 1.8975 - val_accuracy: 0.4738\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7935 - accuracy: 0.7148 - val_loss: 1.9283 - val_accuracy: 0.4616\n",
      "1563/1563 [==============================] - 1s 945us/step - loss: 0.7530 - accuracy: 0.7309\n",
      "313/313 [==============================] - 0s 927us/step - loss: 1.9283 - accuracy: 0.4616\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 161,810\n",
      "Trainable params: 161,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4 hidden layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.7625 - accuracy: 0.3710 - val_loss: 1.5969 - val_accuracy: 0.4365\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5658 - accuracy: 0.4460 - val_loss: 1.5569 - val_accuracy: 0.4557\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4860 - accuracy: 0.4734 - val_loss: 1.4968 - val_accuracy: 0.4684\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4205 - accuracy: 0.4974 - val_loss: 1.4915 - val_accuracy: 0.4701\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3756 - accuracy: 0.5136 - val_loss: 1.4537 - val_accuracy: 0.4890\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 1.3397 - accuracy: 0.5262 - val_loss: 1.4549 - val_accuracy: 0.4831\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3029 - accuracy: 0.5367 - val_loss: 1.4584 - val_accuracy: 0.4876\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2751 - accuracy: 0.5458 - val_loss: 1.4306 - val_accuracy: 0.4958\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2444 - accuracy: 0.5571 - val_loss: 1.4401 - val_accuracy: 0.4974\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2228 - accuracy: 0.5662 - val_loss: 1.4450 - val_accuracy: 0.4870\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2014 - accuracy: 0.5720 - val_loss: 1.4499 - val_accuracy: 0.4922\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1811 - accuracy: 0.5800 - val_loss: 1.4390 - val_accuracy: 0.4999\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1617 - accuracy: 0.5886 - val_loss: 1.4605 - val_accuracy: 0.4906\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1430 - accuracy: 0.5920 - val_loss: 1.4526 - val_accuracy: 0.5050\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1211 - accuracy: 0.5980 - val_loss: 1.4664 - val_accuracy: 0.5025\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1094 - accuracy: 0.6038 - val_loss: 1.4790 - val_accuracy: 0.4925\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0970 - accuracy: 0.6098 - val_loss: 1.4919 - val_accuracy: 0.4981\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0755 - accuracy: 0.6151 - val_loss: 1.4936 - val_accuracy: 0.4989\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0640 - accuracy: 0.6188 - val_loss: 1.5077 - val_accuracy: 0.4924\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0492 - accuracy: 0.6273 - val_loss: 1.5242 - val_accuracy: 0.4992\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0370 - accuracy: 0.6278 - val_loss: 1.5058 - val_accuracy: 0.5002\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0231 - accuracy: 0.6329 - val_loss: 1.5498 - val_accuracy: 0.4923\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0132 - accuracy: 0.6397 - val_loss: 1.5362 - val_accuracy: 0.4978\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9991 - accuracy: 0.6406 - val_loss: 1.5452 - val_accuracy: 0.4981\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9863 - accuracy: 0.6479 - val_loss: 1.5855 - val_accuracy: 0.4919\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9771 - accuracy: 0.6517 - val_loss: 1.5621 - val_accuracy: 0.4967\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9683 - accuracy: 0.6540 - val_loss: 1.5795 - val_accuracy: 0.4918\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9560 - accuracy: 0.6587 - val_loss: 1.5719 - val_accuracy: 0.4950\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9425 - accuracy: 0.6635 - val_loss: 1.6123 - val_accuracy: 0.4915\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9424 - accuracy: 0.6611 - val_loss: 1.6099 - val_accuracy: 0.4972\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9283 - accuracy: 0.6685 - val_loss: 1.6626 - val_accuracy: 0.4859\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9149 - accuracy: 0.6721 - val_loss: 1.6606 - val_accuracy: 0.4855\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9091 - accuracy: 0.6736 - val_loss: 1.6614 - val_accuracy: 0.4830\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8999 - accuracy: 0.6765 - val_loss: 1.6738 - val_accuracy: 0.4844\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8939 - accuracy: 0.6797 - val_loss: 1.7287 - val_accuracy: 0.4876\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8876 - accuracy: 0.6803 - val_loss: 1.6925 - val_accuracy: 0.4969\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8700 - accuracy: 0.6881 - val_loss: 1.6988 - val_accuracy: 0.4910\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8657 - accuracy: 0.6869 - val_loss: 1.7370 - val_accuracy: 0.4884\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8577 - accuracy: 0.6924 - val_loss: 1.7502 - val_accuracy: 0.4836\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8520 - accuracy: 0.6927 - val_loss: 1.7576 - val_accuracy: 0.4867\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8415 - accuracy: 0.6970 - val_loss: 1.7651 - val_accuracy: 0.4851\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8356 - accuracy: 0.6997 - val_loss: 1.7741 - val_accuracy: 0.4795\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8328 - accuracy: 0.6985 - val_loss: 1.7759 - val_accuracy: 0.4879\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8225 - accuracy: 0.7052 - val_loss: 1.7819 - val_accuracy: 0.4827\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8128 - accuracy: 0.7073 - val_loss: 1.8149 - val_accuracy: 0.4827\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8060 - accuracy: 0.7101 - val_loss: 1.8772 - val_accuracy: 0.4795\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8032 - accuracy: 0.7102 - val_loss: 1.8496 - val_accuracy: 0.4791\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7955 - accuracy: 0.7134 - val_loss: 1.8928 - val_accuracy: 0.4730\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7872 - accuracy: 0.7173 - val_loss: 1.8934 - val_accuracy: 0.4778\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7811 - accuracy: 0.7177 - val_loss: 1.9029 - val_accuracy: 0.4807\n",
      "1563/1563 [==============================] - 2s 974us/step - loss: 0.7354 - accuracy: 0.7365\n",
      "313/313 [==============================] - 0s 961us/step - loss: 1.9029 - accuracy: 0.4807\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 50)                153650    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 164,360\n",
      "Trainable params: 164,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5 hidden layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.7539 - accuracy: 0.3736 - val_loss: 1.6277 - val_accuracy: 0.4235\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.5762 - accuracy: 0.4430 - val_loss: 1.5415 - val_accuracy: 0.4559\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4936 - accuracy: 0.4706 - val_loss: 1.5359 - val_accuracy: 0.4577\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.4374 - accuracy: 0.4917 - val_loss: 1.4712 - val_accuracy: 0.4802\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3906 - accuracy: 0.5081 - val_loss: 1.4653 - val_accuracy: 0.4804\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3544 - accuracy: 0.5200 - val_loss: 1.4732 - val_accuracy: 0.4770\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.3204 - accuracy: 0.5314 - val_loss: 1.4482 - val_accuracy: 0.4942\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2934 - accuracy: 0.5420 - val_loss: 1.4447 - val_accuracy: 0.4887\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2667 - accuracy: 0.5513 - val_loss: 1.4418 - val_accuracy: 0.4959\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2450 - accuracy: 0.5590 - val_loss: 1.4609 - val_accuracy: 0.4939\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.2175 - accuracy: 0.5685 - val_loss: 1.4493 - val_accuracy: 0.4908\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1986 - accuracy: 0.5739 - val_loss: 1.4389 - val_accuracy: 0.5003\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.1776 - accuracy: 0.5832 - val_loss: 1.4667 - val_accuracy: 0.4978\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1606 - accuracy: 0.5898 - val_loss: 1.4560 - val_accuracy: 0.4939\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1421 - accuracy: 0.5930 - val_loss: 1.4644 - val_accuracy: 0.4979\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1265 - accuracy: 0.5969 - val_loss: 1.4736 - val_accuracy: 0.4995\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.1105 - accuracy: 0.6038 - val_loss: 1.4805 - val_accuracy: 0.4930\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0947 - accuracy: 0.6105 - val_loss: 1.4780 - val_accuracy: 0.5008\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0832 - accuracy: 0.6133 - val_loss: 1.4950 - val_accuracy: 0.4933\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0677 - accuracy: 0.6199 - val_loss: 1.4999 - val_accuracy: 0.4959\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0516 - accuracy: 0.6257 - val_loss: 1.5191 - val_accuracy: 0.4992\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 1.0400 - accuracy: 0.6302 - val_loss: 1.5054 - val_accuracy: 0.4930\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0267 - accuracy: 0.6336 - val_loss: 1.5292 - val_accuracy: 0.4948\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0140 - accuracy: 0.6390 - val_loss: 1.5266 - val_accuracy: 0.4981\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 1.0039 - accuracy: 0.6424 - val_loss: 1.5533 - val_accuracy: 0.4921\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9935 - accuracy: 0.6444 - val_loss: 1.5884 - val_accuracy: 0.4843\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9811 - accuracy: 0.6500 - val_loss: 1.5800 - val_accuracy: 0.4870\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9700 - accuracy: 0.6551 - val_loss: 1.5910 - val_accuracy: 0.4983\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9543 - accuracy: 0.6593 - val_loss: 1.5977 - val_accuracy: 0.4897\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9515 - accuracy: 0.6595 - val_loss: 1.6129 - val_accuracy: 0.4850\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9366 - accuracy: 0.6653 - val_loss: 1.6385 - val_accuracy: 0.4860\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.9333 - accuracy: 0.6635 - val_loss: 1.6436 - val_accuracy: 0.4860\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9238 - accuracy: 0.6682 - val_loss: 1.6302 - val_accuracy: 0.4903\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9148 - accuracy: 0.6743 - val_loss: 1.6612 - val_accuracy: 0.4857\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.9023 - accuracy: 0.6749 - val_loss: 1.6622 - val_accuracy: 0.4854\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8922 - accuracy: 0.6821 - val_loss: 1.7044 - val_accuracy: 0.4853\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8878 - accuracy: 0.6817 - val_loss: 1.7061 - val_accuracy: 0.4761\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8820 - accuracy: 0.6834 - val_loss: 1.7178 - val_accuracy: 0.4790\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8729 - accuracy: 0.6876 - val_loss: 1.7045 - val_accuracy: 0.4875\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8616 - accuracy: 0.6902 - val_loss: 1.7347 - val_accuracy: 0.4849\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.8528 - accuracy: 0.6937 - val_loss: 1.7676 - val_accuracy: 0.4755\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8490 - accuracy: 0.6937 - val_loss: 1.7352 - val_accuracy: 0.4797\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8411 - accuracy: 0.6962 - val_loss: 1.7615 - val_accuracy: 0.4777\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8356 - accuracy: 0.7007 - val_loss: 1.7650 - val_accuracy: 0.4819\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8198 - accuracy: 0.7057 - val_loss: 1.7805 - val_accuracy: 0.4783\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8233 - accuracy: 0.7030 - val_loss: 1.8245 - val_accuracy: 0.4773\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8116 - accuracy: 0.7074 - val_loss: 1.8354 - val_accuracy: 0.4753\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.8059 - accuracy: 0.7094 - val_loss: 1.8523 - val_accuracy: 0.4755\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7942 - accuracy: 0.7152 - val_loss: 1.8734 - val_accuracy: 0.4807\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.7937 - accuracy: 0.7147 - val_loss: 1.8460 - val_accuracy: 0.4829\n",
      "1563/1563 [==============================] - 2s 992us/step - loss: 0.7478 - accuracy: 0.7310\n",
      "313/313 [==============================] - 0s 983us/step - loss: 1.8460 - accuracy: 0.4829\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y_train_error = []\n",
    "y_test_error = []\n",
    "for i in range(6):\n",
    "    x.append(i)\n",
    "    model = create_model((x_train.shape[1],), no_classes, i, 50)\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    print('%d hidden layers' % i)\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=128, verbose=1, validation_data=(x_test, y_test))\n",
    "    #train error\n",
    "    _, train_accuracy = model.evaluate(x_train, y_train)\n",
    "    train_error = (1 - train_accuracy)*100\n",
    "    y_train_error.append(train_error)\n",
    "    #test_error\n",
    "    _, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    test_error = (1 - test_accuracy)*100\n",
    "    y_test_error.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1cfc0fe9d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"number of hidden layers\")\n",
    "plt.ylabel('test set error %')\n",
    "plt.plot(x, y_train_error, 'b', label='train error')\n",
    "plt.plot(x, y_test_error, 'r', label='test error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('no_hidden_layers___test_set_error_v2.txt', 'w')\n",
    "\n",
    "f.write('number of hidden layers, train error, test error\\n')\n",
    "for i in range(len(x)):\n",
    "    f.write('{}, {}, {}'.format(x[i], y_train_error[i], y_test_error[i]))\n",
    "    f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
